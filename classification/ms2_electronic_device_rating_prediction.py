# -*- coding: utf-8 -*-
"""MS2 Electronic Device Rating Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gzyFoE9UZ6-oCJ4hGwH6z2tkyksoQeEr

# **Step 1: Reading & Exploring Data**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import time
import missingno as msno
import scipy.stats as stats
from sklearn.svm import SVC
from sklearn import metrics
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OrdinalEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold,cross_val_score
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import chi2
from sklearn.model_selection import GridSearchCV
# %matplotlib inline

df = pd.read_csv('/content/ElecDeviceRatingPrediction_Milestone2.csv')

df.head()

df.info()

df.describe()

# @title Distinct Values of Categorical Features
object_columns = df.select_dtypes(include='object').columns
for column in object_columns:
    print(f"Column: {column}")
    print(df[column].unique(),'\n')

distinct_values_dict = {}
for column in object_columns:
    distinct_values_dict[column] = df[column].unique()

print("Number of Duplicates: ",df.duplicated().sum())
print("Data Shape: ",df.shape)

sns.distplot(df['Price'])

sns.distplot(df['Number of Reviews'])

sns.distplot(df['Number of Ratings'])

"""# **Step 2: Preprocessing**"""

df[['os-bits', 'os']] = df['os'].str.split('-bit', n=1, expand=True)


df['os'] = df['os'].str.strip()

df['os-bits'] = pd.to_numeric(df['os-bits'])

#converting categorical values into numerical values.
#There are some columns that have categorical values ,but actually a numerical value

df['ram_gb'] = df['ram_gb'].astype(str).str.replace('GB','')
df['ram_gb'] = pd.to_numeric(df['ram_gb'])

df['ssd'] = df['ssd'].astype(str).str.replace('GB','')
df['ssd'] = pd.to_numeric(df['ssd'])

df['hdd'] = df['hdd'].astype(str).str.replace('GB','')
df['hdd'] = pd.to_numeric(df['hdd'])


df['graphic_card_gb'] = df['graphic_card_gb'].astype(str).str.replace('GB','')
df['graphic_card_gb'] = pd.to_numeric(df['graphic_card_gb'])

"""## **Duplicates Handling**"""

df.isnull().sum()

df = df.drop_duplicates()

print("Number of Duplicates: ",df.duplicated().sum())
print("Data Shape: ",df.shape)

categorical_df = df.select_dtypes(include=['object', 'category'])
categorical_df.head()

numerical_df = df.select_dtypes(include=['float64', 'int64'])
numerical_df.head()

categorical_mode  = {}
categorical_mode  = {c: df[c].mode()[0] for c in categorical_df}
categorical_mode.pop('rating', None)

categorical_mode

numeric_mean = {}
numeric_mean = {c: df[c].mean() for c in numerical_df}

numeric_mean

df.head()

"""## **Feature Encoding**

> **1. Ordinal encoder will be applied to the following ordinal features:**

> *   rating
>*   processor_gnrtn
>*   warranty
>*   processor_name
"""

ordinal_encoder_rating = OrdinalEncoder(categories=[['Good Rating', 'Bad Rating']])
df['rating'] = ordinal_encoder_rating.fit_transform(df[['rating']])
decoded_rating = ordinal_encoder_rating.inverse_transform(df[['rating']])

ordinal_encoder_processor_gnrtn = OrdinalEncoder(categories=[['Not Available','4th', '7th','8th','9th', '10th','11th','12th']])
df['processor_gnrtn']=ordinal_encoder_processor_gnrtn.fit_transform(df[['processor_gnrtn']])
decoded_processor_gnrtn = ordinal_encoder_processor_gnrtn.inverse_transform(df[['processor_gnrtn']])

ordinal_encoder_warranty = OrdinalEncoder(categories=[['No warranty', '1 year', '3 years', '2 years'] ])
df['warranty']=ordinal_encoder_warranty.fit_transform(df[['warranty']])
decoded_warranty = ordinal_encoder_warranty.inverse_transform(df[['warranty']])

ordinal_encoder_processor_name = OrdinalEncoder(categories=[['Celeron Dual', 'Pentium Quad', 'Ryzen 3', 'Core i3', 'Ryzen 5','Ryzen 7','Core i5','Core i7','Ryzen 9','Core i9','M1']])
df['processor_name']=ordinal_encoder_processor_name.fit_transform(df[['processor_name']])
decoded_processor_name = ordinal_encoder_processor_name.inverse_transform(df[['processor_name']])

"""

> **2. Label Encoding will be applied to the following nominal features:**


> *   brand
*   processor_brand
*   ram_type
*   os
*   weight
*   msoffice
*   Touchscreen







"""

label_encoder_brand = LabelEncoder()
df['brand'] = label_encoder_brand.fit_transform(df['brand'])
decoded_brand = label_encoder_brand.inverse_transform(df['brand'])


label_encoder_processor_brand = LabelEncoder()
df['processor_brand'] = label_encoder_processor_brand.fit_transform(df['processor_brand'])
decoded_processor_brand = label_encoder_processor_brand.inverse_transform(df['processor_brand'])


label_encoder_ram_type = LabelEncoder()
df['ram_type'] = label_encoder_ram_type.fit_transform(df['ram_type'])
decoded_ram_type = label_encoder_ram_type.inverse_transform(df['ram_type'])


label_encoder_os = LabelEncoder()
df['os'] = label_encoder_os.fit_transform(df['os'])
decoded_os = label_encoder_os.inverse_transform(df['os'])


label_encoder_weight = LabelEncoder()
df['weight'] = label_encoder_weight.fit_transform(df['weight'])
decoded_weight = label_encoder_weight.inverse_transform(df['weight'])


label_encoder_msoffice = LabelEncoder()
df['msoffice']=label_encoder_msoffice.fit_transform(df['msoffice'])
decoded_msoffice = label_encoder_msoffice.inverse_transform(df['msoffice'])


label_encoder_touchscreen = LabelEncoder()
df['Touchscreen']=label_encoder_touchscreen.fit_transform(df['Touchscreen'])
decoded_Touchscreen = label_encoder_touchscreen.inverse_transform(df['Touchscreen'])

df.head()

"""## **Check If Data is Balnced**"""

type(decoded_rating)

sns.barplot(x=pd.Series(decoded_rating.flatten()).value_counts().index, y=df['rating'].value_counts())
plt.title('Rating Distribution')
plt.show()

class_frequency = pd.Series(decoded_rating.flatten()).value_counts()

print(class_frequency)

"""

> Data shows class imbalance in target column

"""

df.head()

df.columns

df.info()

encoded_categorical_df = df[['brand','processor_brand'	,'processor_name',	'processor_gnrtn',	'ram_type',	'os',	'weight',	'warranty',	'Touchscreen',	'msoffice',	'rating']]

df.head()

df.info()

for col in encoded_categorical_df.columns:
    plt.figure(figsize=(40, 10))
    plt.title(col)
    plt.pie(df[col].value_counts(),
           labels=df[col].unique(),
            shadow=False,
            autopct='%.3f')
    plt.show()

df.head()

df.shape

df.drop('weight',inplace=True,axis=1)

encoded_categorical_df.drop('weight',inplace=True,axis=1)

df.shape

"""## **Feature Scaling**"""

#Normalization
features_to_normalize=['Price']
price_scaler = MinMaxScaler(feature_range=(0, 1))

df[features_to_normalize] = price_scaler.fit_transform(df[features_to_normalize])

df.head()

features_to_normalize=['Number of Ratings']
num_rating_scaler = MinMaxScaler(feature_range=(0, 1))

df[features_to_normalize] = num_rating_scaler.fit_transform(df[features_to_normalize])

df.head()

features_to_normalize=['Number of Reviews']
num_reviews_scaler = MinMaxScaler(feature_range=(0, 1))

df[features_to_normalize] = num_reviews_scaler.fit_transform(df[features_to_normalize])

df.head()

df.info()

categorical_df.head()

"""## **Outlier Handling**"""

numerical_data = df[['Number of Ratings', 'Number of Reviews', 'Price']]
plt.figure(figsize=(12, 8))
sns.boxplot(data=numerical_data, orient="h")
plt.show()

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

iqr_threshold = 3

iqr_ranges = {'Q1': Q1, 'Q3': Q3, 'IQR': IQR, 'Thresh' : iqr_threshold}

outlier_rows = df[((df < (Q1 - iqr_threshold * IQR)) | (df > (Q3 + iqr_threshold * IQR))).any(axis=1)]


for column in numerical_data:
    median_value = df[column].median()
    df.loc[df[column] < (Q1[column] - iqr_threshold * IQR[column]), column] = median_value
    df.loc[df[column] > (Q3[column] + iqr_threshold * IQR[column]), column] = median_value

"""# **Step 3: Feature Selection**

## **Correlation**
"""

corr_matrix = df.corr()
corr_matrix['rating'].sort_values(ascending=False)

"""## **Chi Squared**"""

cat_data = encoded_categorical_df.drop('rating', axis=1)
target = encoded_categorical_df['rating']

# Calculate chi-square scores and p-values
chi2_scores, p_values = chi2(cat_data, target)

# Print chi-square scores and p-values
print(chi2_scores)
print(p_values)

# Create a Series for chi-square scores with column names as index
chi_values = pd.Series(chi2_scores, index=cat_data.columns)
chi_values.sort_values(ascending=False, inplace=True)

# Plot chi-square scores as a bar plot
chi_values.plot.bar()
plt.title('Chi-square Scores')
plt.xlabel('Features')
plt.ylabel('Chi-square Scores')
plt.show()

# Create a Series for p-values with column names as index
p_values_series = pd.Series(p_values, index=cat_data.columns)
p_values_series.sort_values(ascending=False, inplace=True)

# Plot p-values as a bar plot
p_values_series.plot.bar()
plt.title('P-values')
plt.xlabel('Features')
plt.ylabel('P-values')
plt.show()

df.head()

df.drop('processor_name',axis=1,inplace=True)
df.drop('processor_gnrtn',axis=1,inplace=True)
df.drop('processor_brand',axis=1,inplace=True)
df.drop('os',axis=1,inplace=True)
df.drop('brand',axis=1,inplace=True)
df.drop('Touchscreen',axis=1,inplace=True)

df.shape

"""## **ANOVA**"""

numerical_df.head()

encoded_numerical_df = df[['ram_gb','ssd','hdd','graphic_card_gb','Number of Ratings','Number of Reviews','Price','os-bits']]

from scipy.stats import f_oneway

target_column = 'rating'


feature_columns = [col for col in numerical_df.columns if col != target_column]

alpha = 0.05
significant_features = []

for feature_column in feature_columns:
    groups = [df[df[feature_column] == value][target_column] for value in df[feature_column].unique()]
    statistic, p_value = f_oneway(*groups)

    print(f"Feature: {feature_column}")
    print("ANOVA statistic:", statistic)
    print("p-value:", p_value)

    if p_value < alpha:
        print("Reject null hypothesis: There are significant differences between at least two groups.")
        significant_features.append(feature_column)
    else:
        print("Fail to reject null hypothesis: There is no significant difference between the groups.")

    print()

print("Significant features:", significant_features)

df.drop('hdd',axis=1,inplace=True)
df.drop('graphic_card_gb',axis=1,inplace=True)

df.info()

df.shape

df.columns

"""# **Step 4: Split Train & Test Data**"""

X = df[['ram_gb', 'ram_type', 'ssd', 'warranty', 'msoffice', 'Price',
       'Number of Ratings', 'Number of Reviews', 'os-bits']]
Y = df['rating']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42,shuffle=True)

# !pip install imbalanced-learn

# from imblearn.over_sampling import SMOTE
# from imblearn.datasets import make_imbalance
# smote = SMOTE(random_state = 14)
# X_train, Y_train = smote.fit_resample(X_train1, Y_train1)
# Y_train.value_counts().plot(kind='bar')
# plt.title('label balance')
# plt.xlabel('label values')
# plt.ylabel('amount per label')
# plt.show()

"""# **Step 5: Modelling**

## **Logistic Regression**
"""

# from sklearn.model_selection import GridSearchCV
# from sklearn.linear_model import LogisticRegression

# # Define the parameter grid
# param_grid = {
#     'C': [0.001, 0.01, 0.1, 1, 10],  # Regularization parameter
#     'penalty': ['l1', 'l2'],           # Penalty norm
#     'solver': ['liblinear', 'saga','lbfgs']    # Optimization algorithm
# }

# # Create the Logistic Regression model
# lr = LogisticRegression(max_iter=100)

# # Create GridSearchCV
# grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# # Fit the model to the data
# grid_search.fit(X_train, Y_train)

# # Get the best parameters and best score
# best_params = grid_search.best_params_
# best_score = grid_search.best_score_

# print("Best Parameters:", best_params)
# print("Best Score:", best_score)

# # Use the best estimator to make predictions
# best_lr = grid_search.best_estimator_
# Y_train_pred_lr = best_lr.predict(X_train)
# Y_test_pred_lr = best_lr.predict(X_test)

# # Calculate and print accuracy
# train_accuracy_lr = accuracy_score(Y_train, Y_train_pred_lr) * 100
# test_accuracy_lr = accuracy_score(Y_test, Y_test_pred_lr) * 100
# print("Train Accuracy:", train_accuracy_lr)
# print("Test Accuracy:", test_accuracy_lr)

# X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=42,shuffle=True)
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression

lr=LogisticRegression(C=20, penalty = 'l1', solver='liblinear')
lr.fit(X_train,Y_train)
Y_pred_lr = lr.predict(X_test)

Y_pred_lr.shape
score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)
print("The accuracy score achieved using Logistic Regression is: "+str(score_lr)+" %")

Y_train_pred_lr = lr.predict(X_train)
train_score_lr = round(accuracy_score(Y_train_pred_lr, Y_train) * 100, 2)
print("The training accuracy achieved using Logistic Regression is: " + str(train_score_lr) + " %")

"""## **Random Forest**

Random Forest Grid Search
"""

# from sklearn.ensemble import RandomForestClassifier
# from sklearn.model_selection import GridSearchCV

# # Define the parameter grid
# param_grid = {
#     'max_depth': [3, 5, 7],
#     'min_samples_leaf': [1, 5, 10],
#     'min_samples_split': [2, 5, 10],
#     'n_estimators': [16, 32, 64],
# }

# # Create the RandomForestClassifier
# rf = RandomForestClassifier(random_state=42)

# # Create GridSearchCV
# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# # Fit the model to the data
# grid_search.fit(X_train, Y_train)

# # Get the best parameters and best score
# best_params = grid_search.best_params_
# best_score = grid_search.best_score_

# print("Best Parameters:", best_params)
# print("Best Score:", best_score)

# # Use the best estimator to make predictions
# best_rf = grid_search.best_estimator_
# Y_train_pred_rf = best_rf.predict(X_train)
# Y_test_pred_rf = best_rf.predict(X_test)

# # Calculate and print accuracy
# train_accuracy_rf = accuracy_score(Y_train, Y_train_pred_rf) * 100
# test_accuracy_rf = accuracy_score(Y_test, Y_test_pred_rf) * 100
# print("Train Accuracy:", train_accuracy_rf)
# print("Test Accuracy:", test_accuracy_rf)

from sklearn.ensemble import RandomForestClassifier


rf = RandomForestClassifier(max_depth= 5, n_estimators = 64, random_state= 42)
rf.fit(X_train, Y_train)
Y_test_pred_rf = rf.predict(X_test)
Y_train_pred_rf = rf.predict(X_train)
print(Y_test_pred_rf.shape)
print(Y_train_pred_rf.shape)


train_accuracy_rf = round(accuracy_score(Y_train_pred_rf, Y_train) * 100, 2)
print("The train accuracy score achieved using RandomForestClassifier is: "+str(train_accuracy_rf)+" %")

score_rf = round(accuracy_score(Y_test_pred_rf,Y_test)*100,2)
print("The Test accuracy score achieved using RandomForestClassifier is: "+str(score_rf)+" %")

"""## **Decision Tree**"""

# from sklearn.tree import DecisionTreeClassifier
# from sklearn.model_selection import GridSearchCV
# from sklearn.metrics import accuracy_score

# # Create Decision Tree Classifier object
# dt_classifier = DecisionTreeClassifier(random_state=42)

# # Define the hyperparameter grid
# param_grid = {
#     'criterion': ['gini'],
#     'splitter': ['best'],
#     'max_depth': [5, 10, 20],
#     'min_samples_leaf': [1, 2, 3],
#     'max_features': [ 'sqrt', 'log2']
# }

# # Create GridSearchCV object
# grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')

# # Perform GridSearchCV
# grid_search.fit(X_train, Y_train)

# # Get the best parameters
# best_params = grid_search.best_params_
# print("Best Hyperparameters:", best_params)

# # Make predictions on the test set using the best model
# best_dt_classifier = grid_search.best_estimator_
# y_pred = best_dt_classifier.predict(X_test)

# # Evaluate accuracy
# accuracy = accuracy_score(Y_test, y_pred)
# print("Test Accuracy:", accuracy*100)

# # Make predictions on the training set using the best model
# y_train_pred = best_dt_classifier.predict(X_train)

# # Evaluate training accuracy
# train_accuracy = accuracy_score(Y_train, y_train_pred)
# print("Training Accuracy:", train_accuracy*100)

from sklearn.tree import DecisionTreeClassifier
dt_classifier = DecisionTreeClassifier(random_state=42,max_depth=3, min_samples_leaf=15,criterion = 'gini')


# Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}

# Train the Decision Tree Classifier
dt_classifier.fit(X_train, Y_train)

# Make predictions on the test set
y_pred = dt_classifier.predict(X_test)

# Evaluate accuracy
accuracy = accuracy_score(Y_test, y_pred)
print("Test Accuracy:", accuracy*100)

# Make predictions on the training set
y_train_pred = dt_classifier.predict(X_train)

# Evaluate training accuracy
train_accuracy = accuracy_score(Y_train, y_train_pred)
print("Training Accuracy:", train_accuracy*100)

"""## **Ensemble Learning**

### **1.   XGBoost**
"""

# from xgboost import XGBClassifier
# from sklearn.model_selection import GridSearchCV

# # Create XGBClassifier instance
# XGB = XGBClassifier(random_state=42)

# # Define the hyperparameters grid
# param_grid = {
#     'max_depth': [3, 5, 7],
#     'subsample': [0.8, 1.0],
#     'n_estimators': [50, 100, 200],
#     'min_child_weight': [1, 5, 10]
# }

# # Instantiate GridSearchCV
# grid_search = GridSearchCV(estimator=XGB, param_grid=param_grid, cv=5, scoring='accuracy')

# # Perform grid search on the training data
# grid_search.fit(X_train, Y_train)

# # Get the best parameters and best score
# best_params = grid_search.best_params_
# best_score = grid_search.best_score_

# # Print the best parameters and best score
# print("Best parameters found:", best_params)
# print("Best cross-validation score:", best_score)

# # Get the best model
# best_model = grid_search.best_estimator_

# # Evaluate the best model on the test data
# test_accuracy = best_model.score(X_test, Y_test)
# print("Test accuracy of the best model:", test_accuracy)

from xgboost import XGBClassifier
XGB = XGBClassifier(max_depth=10, subsample=1, n_estimators=100, min_child_weight=5, random_state=42)
XGB.fit(X_train, Y_train)
print('Model train accuracy score: {0:0.4f}'. format(XGB.score(X_train,Y_train)*100))
print('Model test accuracy score: {0:0.4f}'. format(XGB.score(X_test,Y_test)*100))

"""### **2.   AdaBoost**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
dtclf = DecisionTreeClassifier(max_depth=4, criterion='gini',
                               random_state=100)
clf = AdaBoostClassifier(base_estimator=dtclf,
                            n_estimators=50,
                            learning_rate=0.6,
                            algorithm='SAMME.R',
                            random_state=300)

clf.fit(X_train, Y_train)
print('Model train accuracy score: {0:0.4f}'. format(clf.score(X_train,Y_train)*100))
print('Model test accuracy score: {0:0.4f}'. format(clf.score(X_test,Y_test)*100))

classifiers = {
    'RandomForest':  RandomForestClassifier(max_depth= None, max_features= 'auto', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 100, random_state= 125),
    'AdaBoost': AdaBoostClassifier(base_estimator=dtclf,
                            n_estimators=50,
                            learning_rate=0.6,
                            algorithm='SAMME.R',
                            random_state=300),
    'XGBoost': XGBClassifier(max_depth=3, subsample=1, n_estimators=50, min_child_weight=1, random_state=42),
    'DecisionTree': DecisionTreeClassifier(random_state=105)
}

accuracy_scores = []
training_times = []
test_times = []

for clf_name, clf in classifiers.items():
    # Measure training time
    start_train_time = time.time()
    clf.fit(X_train, Y_train)
    end_train_time = time.time()
    training_time = end_train_time - start_train_time
    training_times.append(training_time)

    # Make predictions on the test set and measure test time
    start_test_time = time.time()
    y_pred = clf.predict(X_test)
    end_test_time = time.time()
    test_time = end_test_time - start_test_time
    test_times.append(test_time)

    # Calculate accuracy score
    accuracy = accuracy_score(Y_test, y_pred)
    accuracy_scores.append(accuracy)


plt.figure(figsize=(15, 5))

# Plot accuracy
plt.subplot(1, 3, 1)
plt.bar(classifiers.keys(), accuracy_scores, color='skyblue')
plt.title('Classification Accuracy')
plt.ylabel('Accuracy')

# Plot training time
plt.subplot(1, 3, 2)
plt.bar(classifiers.keys(), training_times, color='lightgreen')
plt.title('Total Training Time')
plt.ylabel('Time (seconds)')

# Plot test time
plt.subplot(1, 3, 3)
plt.bar(classifiers.keys(), test_times, color='salmon')
plt.title('Total Test Time')
plt.ylabel('Time (seconds)')

plt.tight_layout()
plt.show()

"""## **Step 6: Pickling**"""

import pickle

"""### **1. Pickle Models**"""

pickle.dump(lr, open('logisticRegression.pkl', 'wb'))
pickle.dump(rf, open('randomForest.pkl', 'wb'))
pickle.dump(dt_classifier, open('decisionTree.pkl', 'wb'))
pickle.dump(XGB, open('XGBoost.pkl', 'wb'))
pickle.dump(clf, open('AdaBoost.pkl', 'wb'))

"""### **2. Pickle Encoding**"""

ordinal_encoders = {
    'OE_processor_gnrtn' : ordinal_encoder_processor_gnrtn,
    'OE_warranty' : ordinal_encoder_warranty,
    'OE_processor_name' : ordinal_encoder_processor_name,
}

label_encoders = {
    'LE_brand' : label_encoder_brand,
    'LE_processor_brand' : label_encoder_processor_brand,
    'LE_ram_type' : label_encoder_ram_type,
    'LE_os' : label_encoder_os,
    'LE_weight' : label_encoder_weight,
    'LE_msoffice' : label_encoder_msoffice,
    'LE_touchscreen' : label_encoder_touchscreen,
}

pickle.dump(ordinal_encoders, open('ordinalEncoding.pkl', 'wb'))
pickle.dump(label_encoders, open('labelEncoding.pkl', 'wb'))

"""### **3. Pickle Normalization**"""

normalization_fns = {
    'normalize_price': price_scaler,
    'normalize_num_rating' : num_rating_scaler,
    'normalize_num_reviews' : num_reviews_scaler
}

#pickling normalization
pickle.dump(normalization_fns, open('normalizationFns.pkl', 'wb'))

"""### **4. Pickle Constant Values**

"""

preproc_values = {
    'column_means' : numeric_mean,
    'column_modes' : categorical_mode
}

#pickling const values
pickle.dump(preproc_values, open('preprocValues.pkl', 'wb'))

pickle.dump(distinct_values_dict, open('distinctValues.pkl', 'wb'))

# from sklearn.model_selection import GridSearchCV

# # Define the parameter grid to search
# param_grid = {
#     'base_estimator__max_depth': [3, 4, 5],
#     'n_estimators': [50, 60, 70],
#     'learning_rate': [0.6, 0.8, 1.0],
# }

# # Create the grid search object
# grid_search = GridSearchCV(estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=100),
#                                                        algorithm='SAMME.R',
#                                                        random_state=300),
#                            param_grid=param_grid,
#                            cv=5,  # 5-fold cross-validation
#                            scoring='accuracy',  # or other appropriate scoring metric
#                            n_jobs=-1)  # Use all available cores

# # Fit the grid search to the data
# grid_search.fit(X_train, Y_train)

# # Print the best parameters found
# print("Best parameters:", grid_search.best_params_)

# # Get the best model
# best_model = grid_search.best_estimator_

# # Print the model accuracy on training and test sets using the best model
# print('Best model train accuracy score: {0:0.4f}'.format(best_model.score(X_train, Y_train) * 100))
# print('Best model test accuracy score: {0:0.4f}'.format(best_model.score(X_test, Y_test) * 100))

# from sklearn.model_selection import GridSearchCV

# # Define the parameter grid to search
# param_grid = {
#     'max_depth': [3, 4, 5],
#     'subsample': [0.8, 1.0],
#     'n_estimators': [50, 100, 150],
#     'min_child_weight': [1, 2, 3]
# }

# # Create the grid search object
# grid_search = GridSearchCV(estimator=XGBClassifier(random_state=42),
#                            param_grid=param_grid,
#                            cv=5,  # 5-fold cross-validation
#                            scoring='accuracy',  # or other appropriate scoring metric
#                            n_jobs=-1)  # Use all available cores

# # Fit the grid search to the data
# grid_search.fit(X_train, Y_train)

# # Print the best parameters found
# print("Best parameters:", grid_search.best_params_)

# # Get the best model
# best_model = grid_search.best_estimator_

# # Print the model accuracy on training and test sets using the best model
# print('Best model accuracy score on training set: {0:0.4f}'.format(best_model.score(X_train, Y_train) * 100))
# print('Best model accuracy score on test set: {0:0.4f}'.format(best_model.score(X_test, Y_test) * 100))

# from sklearn.model_selection import GridSearchCV
# from sklearn.svm import SVC
# from sklearn.metrics import accuracy_score

# # Define the parameter grid for grid search
# param_grid = {
#     'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Different values of C (regularization parameter)
#     'kernel': ['linear', 'rbf', 'poly'],  # Different kernel functions
# }

# # Create an SVM classifier
# svm_classifier = SVC()

# # Initialize GridSearchCV with the classifier and parameter grid
# grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')

# # Fit the model to your training data
# grid_search.fit(X_train, Y_train)

# # Print the best parameters found
# print("Best parameters:", grid_search.best_params_)

# accuracy = accuracy_score(Y_train, y_train_pred)
# print("Accuracy train:", accuracy)


# accuracy = accuracy_score(Y_test, y_text_pred)
# print("Accuracy:", accuracy)